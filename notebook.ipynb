{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要的信息：entryID\\Taxon ID of the species\\sequence   OBO中的几个term: Molecular Function (MF), Biological Process (BP), and Cellular Component (CC)\n",
    "https://github.com/claradepaolis/InformationAccretion (IA文件评分)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/zane/Data/protein/cafa-5-protein-function-prediction/sample_submission.tsv\n",
      "/Users/zane/Data/protein/cafa-5-protein-function-prediction/.DS_Store\n",
      "/Users/zane/Data/protein/cafa-5-protein-function-prediction/IA.txt\n",
      "/Users/zane/Data/protein/cafa-5-protein-function-prediction/Test (Targets)/.DS_Store\n",
      "/Users/zane/Data/protein/cafa-5-protein-function-prediction/Test (Targets)/testsuperset.fasta\n",
      "/Users/zane/Data/protein/cafa-5-protein-function-prediction/Test (Targets)/testsuperset-taxon-list.tsv\n",
      "/Users/zane/Data/protein/cafa-5-protein-function-prediction/Train/train_taxonomy.tsv\n",
      "/Users/zane/Data/protein/cafa-5-protein-function-prediction/Train/.DS_Store\n",
      "/Users/zane/Data/protein/cafa-5-protein-function-prediction/Train/train_terms.tsv\n",
      "/Users/zane/Data/protein/cafa-5-protein-function-prediction/Train/go-basic.obo\n",
      "/Users/zane/Data/protein/cafa-5-protein-function-prediction/Train/train_sequences.fasta\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "home_dir = os.environ.get('HOME')\n",
    "directory_path = os.path.join(home_dir, 'Data', 'protein', 'cafa-5-protein-function-prediction')\n",
    "\n",
    "for dirname, _, filenames in os.walk(directory_path):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#处理/Train/train_sequences.fasta\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_dict = {}\n",
    "for seq_record in SeqIO.parse(os.path.join(directory_path, 'Train', 'train_sequences.fasta'), \"fasta\"):\n",
    "    sequences_dict[seq_record.id] = str(seq_record.seq)\n",
    "sequences = pd.DataFrame(list(sequences_dict.items()), columns=['EntryID', 'Sequence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_annotations = pd.read_csv(os.path.join(directory_path, 'Train', 'train_taxonomy.tsv') ,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把两个表合并\n",
    "train = pd.merge(sequences, sequences_annotations, on='EntryID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用obonet处理/Train/go-basic.obo\n",
    "# !pip install obonet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip show pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             term                                               Name  \\\n",
      "0      GO:0000001                          mitochondrion inheritance   \n",
      "1      GO:0000002                   mitochondrial genome maintenance   \n",
      "2      GO:0000003                                       reproduction   \n",
      "3      GO:0000006  high-affinity zinc transmembrane transporter a...   \n",
      "4      GO:0000007  low-affinity zinc ion transmembrane transporte...   \n",
      "...           ...                                                ...   \n",
      "43243  GO:2001313  UDP-4-deoxy-4-formamido-beta-L-arabinopyranose...   \n",
      "43244  GO:2001314  UDP-4-deoxy-4-formamido-beta-L-arabinopyranose...   \n",
      "43245  GO:2001315  UDP-4-deoxy-4-formamido-beta-L-arabinopyranose...   \n",
      "43246  GO:2001316                       kojic acid metabolic process   \n",
      "43247  GO:2001317                    kojic acid biosynthetic process   \n",
      "\n",
      "                Namespace  \n",
      "0      biological_process  \n",
      "1      biological_process  \n",
      "2      biological_process  \n",
      "3      molecular_function  \n",
      "4      molecular_function  \n",
      "...                   ...  \n",
      "43243  biological_process  \n",
      "43244  biological_process  \n",
      "43245  biological_process  \n",
      "43246  biological_process  \n",
      "43247  biological_process  \n",
      "\n",
      "[43248 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import obonet\n",
    "import pandas as pd\n",
    "\n",
    "# 读取OBO文件并构建网络图\n",
    "def read_obo(file_path):\n",
    "    return obonet.read_obo(file_path)\n",
    "\n",
    "# 提取指定命名空间的term并返回DataFrame\n",
    "def extract_terms(graph, namespaces):\n",
    "    terms_list = []\n",
    "    for node, data in graph.nodes(data=True):\n",
    "        if 'namespace' in data and data['namespace'] in namespaces:\n",
    "            terms_list.append({\n",
    "                'ID': node,\n",
    "                'Name': data['name'],\n",
    "                'Namespace': data['namespace']\n",
    "            })\n",
    "    return pd.DataFrame(terms_list)\n",
    "\n",
    "# 主程序\n",
    "def main(par):\n",
    "    # 读取OBO文件并构建网络图\n",
    "    graph = read_obo(par)\n",
    "    # 提取GO ID和指定命名空间的term\n",
    "    namespaces = {\"molecular_function\", \"biological_process\", \"cellular_component\"}\n",
    "    terms_df = extract_terms(graph, namespaces)\n",
    "    terms_df.columns = ['term', 'Name', 'Namespace']  # 重命名列\n",
    "    return terms_df\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    par = os.path.join(directory_path, 'Train', 'go-basic.obo')\n",
    "    # par = \"../cafa-5-protein-function-prediction/Train/go-basic.obo\"\n",
    "    obo_info = main(par)\n",
    "    print(obo_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读入train_terms.tsv\n",
    "sequences_terms = pd.read_csv(os.path.join(directory_path, 'Train', 'train_terms.tsv') ,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "obo_info2=pd.merge(obo_info, sequences_terms, on='term')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#这个是最终的数据表\n",
    "train_total=pd.merge(train, obo_info2, on='EntryID').iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EntryID</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>taxonomyID</th>\n",
       "      <th>term</th>\n",
       "      <th>Name</th>\n",
       "      <th>Namespace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P20536</td>\n",
       "      <td>MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...</td>\n",
       "      <td>10249</td>\n",
       "      <td>GO:0003674</td>\n",
       "      <td>molecular_function</td>\n",
       "      <td>molecular_function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P20536</td>\n",
       "      <td>MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...</td>\n",
       "      <td>10249</td>\n",
       "      <td>GO:0005488</td>\n",
       "      <td>binding</td>\n",
       "      <td>molecular_function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P20536</td>\n",
       "      <td>MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...</td>\n",
       "      <td>10249</td>\n",
       "      <td>GO:0005515</td>\n",
       "      <td>protein binding</td>\n",
       "      <td>molecular_function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P20536</td>\n",
       "      <td>MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...</td>\n",
       "      <td>10249</td>\n",
       "      <td>GO:0006139</td>\n",
       "      <td>nucleobase-containing compound metabolic process</td>\n",
       "      <td>biological_process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P20536</td>\n",
       "      <td>MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...</td>\n",
       "      <td>10249</td>\n",
       "      <td>GO:0006259</td>\n",
       "      <td>DNA metabolic process</td>\n",
       "      <td>biological_process</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5363858</th>\n",
       "      <td>A0A8I6GHU0</td>\n",
       "      <td>HCISSLKLTAFFKRSFLLSPEKHLVLLRDGRTLIGFLRSIDQFANL...</td>\n",
       "      <td>10116</td>\n",
       "      <td>GO:0110165</td>\n",
       "      <td>cellular anatomical entity</td>\n",
       "      <td>cellular_component</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5363859</th>\n",
       "      <td>A0A8I6GHU0</td>\n",
       "      <td>HCISSLKLTAFFKRSFLLSPEKHLVLLRDGRTLIGFLRSIDQFANL...</td>\n",
       "      <td>10116</td>\n",
       "      <td>GO:0120025</td>\n",
       "      <td>plasma membrane bounded cell projection</td>\n",
       "      <td>cellular_component</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5363860</th>\n",
       "      <td>A0A8I6GHU0</td>\n",
       "      <td>HCISSLKLTAFFKRSFLLSPEKHLVLLRDGRTLIGFLRSIDQFANL...</td>\n",
       "      <td>10116</td>\n",
       "      <td>GO:1901363</td>\n",
       "      <td>heterocyclic compound binding</td>\n",
       "      <td>molecular_function</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5363861</th>\n",
       "      <td>A0A8I6GHU0</td>\n",
       "      <td>HCISSLKLTAFFKRSFLLSPEKHLVLLRDGRTLIGFLRSIDQFANL...</td>\n",
       "      <td>10116</td>\n",
       "      <td>GO:1990124</td>\n",
       "      <td>messenger ribonucleoprotein complex</td>\n",
       "      <td>cellular_component</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5363862</th>\n",
       "      <td>A0A8I6GHU0</td>\n",
       "      <td>HCISSLKLTAFFKRSFLLSPEKHLVLLRDGRTLIGFLRSIDQFANL...</td>\n",
       "      <td>10116</td>\n",
       "      <td>GO:1990904</td>\n",
       "      <td>ribonucleoprotein complex</td>\n",
       "      <td>cellular_component</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5363863 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            EntryID                                           Sequence  \\\n",
       "0            P20536  MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...   \n",
       "1            P20536  MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...   \n",
       "2            P20536  MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...   \n",
       "3            P20536  MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...   \n",
       "4            P20536  MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...   \n",
       "...             ...                                                ...   \n",
       "5363858  A0A8I6GHU0  HCISSLKLTAFFKRSFLLSPEKHLVLLRDGRTLIGFLRSIDQFANL...   \n",
       "5363859  A0A8I6GHU0  HCISSLKLTAFFKRSFLLSPEKHLVLLRDGRTLIGFLRSIDQFANL...   \n",
       "5363860  A0A8I6GHU0  HCISSLKLTAFFKRSFLLSPEKHLVLLRDGRTLIGFLRSIDQFANL...   \n",
       "5363861  A0A8I6GHU0  HCISSLKLTAFFKRSFLLSPEKHLVLLRDGRTLIGFLRSIDQFANL...   \n",
       "5363862  A0A8I6GHU0  HCISSLKLTAFFKRSFLLSPEKHLVLLRDGRTLIGFLRSIDQFANL...   \n",
       "\n",
       "         taxonomyID        term  \\\n",
       "0             10249  GO:0003674   \n",
       "1             10249  GO:0005488   \n",
       "2             10249  GO:0005515   \n",
       "3             10249  GO:0006139   \n",
       "4             10249  GO:0006259   \n",
       "...             ...         ...   \n",
       "5363858       10116  GO:0110165   \n",
       "5363859       10116  GO:0120025   \n",
       "5363860       10116  GO:1901363   \n",
       "5363861       10116  GO:1990124   \n",
       "5363862       10116  GO:1990904   \n",
       "\n",
       "                                                     Name           Namespace  \n",
       "0                                      molecular_function  molecular_function  \n",
       "1                                                 binding  molecular_function  \n",
       "2                                         protein binding  molecular_function  \n",
       "3        nucleobase-containing compound metabolic process  biological_process  \n",
       "4                                   DNA metabolic process  biological_process  \n",
       "...                                                   ...                 ...  \n",
       "5363858                        cellular anatomical entity  cellular_component  \n",
       "5363859           plasma membrane bounded cell projection  cellular_component  \n",
       "5363860                     heterocyclic compound binding  molecular_function  \n",
       "5363861               messenger ribonucleoprotein complex  cellular_component  \n",
       "5363862                         ribonucleoprotein complex  cellular_component  \n",
       "\n",
       "[5363863 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from transformers import EsmTokenizer, EsmModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/biotorch/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'ESMTokenizer'. \n",
      "The class this function is called from is 'EsmTokenizer'.\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm-1b and are newly initialized: ['esm.contact_head.regression.bias', 'esm.contact_head.regression.weight', 'esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized input IDs: tensor([[ 0, 20, 15, 11,  4,  4,  7,  7,  7,  7,  7,  7,  4,  5,  4,  5,  7,  4,\n",
      "          5,  5,  5,  5,  5,  5,  5,  5,  5,  2]])\n",
      "Embedding shape: torch.Size([1, 28, 1280])\n",
      "Embedding: tensor([[[ 2.8017e-01,  3.9156e-02, -2.0031e-02,  ..., -1.7287e-02,\n",
      "          -1.8021e-01, -2.0528e-01],\n",
      "         [-3.2456e-02, -1.7327e-02,  3.6042e-02,  ..., -5.8190e-02,\n",
      "           8.5993e-02, -4.8921e-01],\n",
      "         [-6.8467e-03, -1.9018e-02, -2.2709e-02,  ..., -5.0332e-02,\n",
      "           5.1199e-02, -4.7812e-01],\n",
      "         ...,\n",
      "         [-3.7725e-05, -5.0551e-03, -1.7264e-02,  ..., -2.8736e-02,\n",
      "           6.5339e-02, -5.1349e-01],\n",
      "         [-1.1798e-02,  2.4026e-03, -5.3339e-03,  ..., -3.1110e-02,\n",
      "           8.3229e-02, -4.9574e-01],\n",
      "         [-3.1180e-02, -8.2870e-03, -1.4255e-02,  ..., -7.7869e-03,\n",
      "           9.0788e-02, -4.8007e-01]]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import EsmTokenizer, EsmModel\n",
    "import torch\n",
    "\n",
    "# 加载预训练的ESM模型和tokenizer\n",
    "model_name = \"facebook/esm-1b\"\n",
    "tokenizer = EsmTokenizer.from_pretrained(model_name)\n",
    "model = EsmModel.from_pretrained(model_name)\n",
    "\n",
    "# 输入蛋白质序列\n",
    "sequence = \"MKTLLVVVVVVLALAVLAAAAAAAAA\"\n",
    "\n",
    "# 将序列转换为模型输入\n",
    "inputs = tokenizer(sequence, return_tensors=\"pt\")\n",
    "\n",
    "# 打印tokenizer的工作细节\n",
    "print(\"Tokenized input IDs:\", inputs['input_ids'])\n",
    "\n",
    "# 获取模型输出（嵌入向量）\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    embedding = outputs.last_hidden_state\n",
    "\n",
    "# 打印嵌入向量\n",
    "print(\"Embedding shape:\", embedding.shape)\n",
    "print(\"Embedding:\", embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/biotorch/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'ESMTokenizer'. \n",
      "The class this function is called from is 'EsmTokenizer'.\n",
      "Some weights of EsmModel were not initialized from the model checkpoint at facebook/esm-1b and are newly initialized: ['esm.contact_head.regression.bias', 'esm.contact_head.regression.weight', 'esm.pooler.dense.bias', 'esm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/var/folders/qc/w1hk3rk56nj4rcdqmlb7lrnw0000gn/T/ipykernel_17746/3636160728.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_train_total['Embedding'] = subset_train_total['Sequence'].apply(get_embedding)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EntryID</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P20536</td>\n",
       "      <td>MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...</td>\n",
       "      <td>[[[tensor(0.4123), tensor(0.0939), tensor(-0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P20536</td>\n",
       "      <td>MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...</td>\n",
       "      <td>[[[tensor(0.4123), tensor(0.0939), tensor(-0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P20536</td>\n",
       "      <td>MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...</td>\n",
       "      <td>[[[tensor(0.4123), tensor(0.0939), tensor(-0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P20536</td>\n",
       "      <td>MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...</td>\n",
       "      <td>[[[tensor(0.4123), tensor(0.0939), tensor(-0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P20536</td>\n",
       "      <td>MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...</td>\n",
       "      <td>[[[tensor(0.4123), tensor(0.0939), tensor(-0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P20536</td>\n",
       "      <td>MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...</td>\n",
       "      <td>[[[tensor(0.4123), tensor(0.0939), tensor(-0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P20536</td>\n",
       "      <td>MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...</td>\n",
       "      <td>[[[tensor(0.4123), tensor(0.0939), tensor(-0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  EntryID                                           Sequence  \\\n",
       "0  P20536  MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...   \n",
       "1  P20536  MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...   \n",
       "2  P20536  MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...   \n",
       "3  P20536  MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...   \n",
       "4  P20536  MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...   \n",
       "5  P20536  MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...   \n",
       "6  P20536  MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...   \n",
       "\n",
       "                                           Embedding  \n",
       "0  [[[tensor(0.4123), tensor(0.0939), tensor(-0.0...  \n",
       "1  [[[tensor(0.4123), tensor(0.0939), tensor(-0.0...  \n",
       "2  [[[tensor(0.4123), tensor(0.0939), tensor(-0.0...  \n",
       "3  [[[tensor(0.4123), tensor(0.0939), tensor(-0.0...  \n",
       "4  [[[tensor(0.4123), tensor(0.0939), tensor(-0.0...  \n",
       "5  [[[tensor(0.4123), tensor(0.0939), tensor(-0.0...  \n",
       "6  [[[tensor(0.4123), tensor(0.0939), tensor(-0.0...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_train_total = train_total.head(7)\n",
    "\n",
    "model_name = \"facebook/esm-1b\"\n",
    "tokenizer = EsmTokenizer.from_pretrained(model_name)\n",
    "model = EsmModel.from_pretrained(model_name)\n",
    "\n",
    "def get_embedding(sequence):\n",
    "    inputs = tokenizer(sequence, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state\n",
    "\n",
    "subset_train_total['Embedding'] = subset_train_total['Sequence'].apply(get_embedding)\n",
    "\n",
    "# print(subset_train_total[['EntryID', 'Sequence', 'Embedding']])\n",
    "subset_train_total[['EntryID', 'Sequence', 'Embedding']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EntryID</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>taxonomyID</th>\n",
       "      <th>term</th>\n",
       "      <th>Name</th>\n",
       "      <th>Namespace</th>\n",
       "      <th>Embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P20536</td>\n",
       "      <td>MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...</td>\n",
       "      <td>10249</td>\n",
       "      <td>GO:0003674</td>\n",
       "      <td>molecular_function</td>\n",
       "      <td>molecular_function</td>\n",
       "      <td>[[[tensor(0.4123), tensor(0.0939), tensor(-0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P20536</td>\n",
       "      <td>MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...</td>\n",
       "      <td>10249</td>\n",
       "      <td>GO:0005488</td>\n",
       "      <td>binding</td>\n",
       "      <td>molecular_function</td>\n",
       "      <td>[[[tensor(0.4123), tensor(0.0939), tensor(-0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P20536</td>\n",
       "      <td>MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...</td>\n",
       "      <td>10249</td>\n",
       "      <td>GO:0005515</td>\n",
       "      <td>protein binding</td>\n",
       "      <td>molecular_function</td>\n",
       "      <td>[[[tensor(0.4123), tensor(0.0939), tensor(-0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P20536</td>\n",
       "      <td>MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...</td>\n",
       "      <td>10249</td>\n",
       "      <td>GO:0006139</td>\n",
       "      <td>nucleobase-containing compound metabolic process</td>\n",
       "      <td>biological_process</td>\n",
       "      <td>[[[tensor(0.4123), tensor(0.0939), tensor(-0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P20536</td>\n",
       "      <td>MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...</td>\n",
       "      <td>10249</td>\n",
       "      <td>GO:0006259</td>\n",
       "      <td>DNA metabolic process</td>\n",
       "      <td>biological_process</td>\n",
       "      <td>[[[tensor(0.4123), tensor(0.0939), tensor(-0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  EntryID                                           Sequence  taxonomyID  \\\n",
       "0  P20536  MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...       10249   \n",
       "1  P20536  MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...       10249   \n",
       "2  P20536  MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...       10249   \n",
       "3  P20536  MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...       10249   \n",
       "4  P20536  MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...       10249   \n",
       "\n",
       "         term                                              Name  \\\n",
       "0  GO:0003674                                molecular_function   \n",
       "1  GO:0005488                                           binding   \n",
       "2  GO:0005515                                   protein binding   \n",
       "3  GO:0006139  nucleobase-containing compound metabolic process   \n",
       "4  GO:0006259                             DNA metabolic process   \n",
       "\n",
       "            Namespace                                          Embedding  \n",
       "0  molecular_function  [[[tensor(0.4123), tensor(0.0939), tensor(-0.0...  \n",
       "1  molecular_function  [[[tensor(0.4123), tensor(0.0939), tensor(-0.0...  \n",
       "2  molecular_function  [[[tensor(0.4123), tensor(0.0939), tensor(-0.0...  \n",
       "3  biological_process  [[[tensor(0.4123), tensor(0.0939), tensor(-0.0...  \n",
       "4  biological_process  [[[tensor(0.4123), tensor(0.0939), tensor(-0.0...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_train_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>EL_Embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GO:0000001</td>\n",
       "      <td>[-0.38843499858703834, 0.5903889354963208, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GO:0000002</td>\n",
       "      <td>[0.21704287287170954, -1.3415500185983502, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GO:0000003</td>\n",
       "      <td>[-0.21563976788206762, -1.5438431535317647, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GO:0000006</td>\n",
       "      <td>[1.3843893747114067, 0.643525358487707, -2.031...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GO:0000007</td>\n",
       "      <td>[-1.0187966626761569, -0.008660862465717607, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         term                                       EL_Embedding\n",
       "0  GO:0000001  [-0.38843499858703834, 0.5903889354963208, -0....\n",
       "1  GO:0000002  [0.21704287287170954, -1.3415500185983502, -1....\n",
       "2  GO:0000003  [-0.21563976788206762, -1.5438431535317647, 0....\n",
       "3  GO:0000006  [1.3843893747114067, 0.643525358487707, -2.031...\n",
       "4  GO:0000007  [-1.0187966626761569, -0.008660862465717607, 1..."
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 提取GO术语并生成EL Embeddings\n",
    "def extract_terms_and_generate_embeddings(graph, namespaces, embedding_dim, max_terms=5):\n",
    "    terms = []\n",
    "    embeddings = []\n",
    "    count = 0\n",
    "    for node, data in graph.nodes(data=True):\n",
    "        if 'namespace' in data and data['namespace'] in namespaces:\n",
    "            terms.append(node)\n",
    "            embeddings.append(np.random.randn(embedding_dim))  # 示例中用随机向量表示\n",
    "            count += 1\n",
    "            if count >= max_terms:\n",
    "                break\n",
    "    return terms, np.array(embeddings)\n",
    "\n",
    "# 假设EL Embedding的维度为256\n",
    "embedding_dim = 256\n",
    "graph = read_obo(par)\n",
    "terms, embeddings = extract_terms_and_generate_embeddings(graph, {\"molecular_function\", \"biological_process\", \"cellular_component\"}, embedding_dim, max_terms=5)\n",
    "\n",
    "# 将GO术语和嵌入表示存储在DataFrame中\n",
    "terms_df = pd.DataFrame({'term': terms, 'EL_Embedding': list(embeddings)})\n",
    "\n",
    "# 打印部分结果\n",
    "terms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from transformers import EsmTokenizer, EsmModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import obonet\n",
    "\n",
    "# 定义MLP模型\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qc/w1hk3rk56nj4rcdqmlb7lrnw0000gn/T/ipykernel_17746/2471869999.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  subset_train_total['Projected_Embedding'] = subset_train_total['Embedding'].apply(lambda x: project_embedding(x.mean(dim=1).squeeze().numpy()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  EntryID                                           Sequence  taxonomyID  \\\n",
      "0  P20536  MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...       10249   \n",
      "1  P20536  MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...       10249   \n",
      "2  P20536  MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...       10249   \n",
      "3  P20536  MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...       10249   \n",
      "4  P20536  MNSVTVSHAPYTITYHDDWEPVMSQLVEFYNEVASWLLRDETSPIP...       10249   \n",
      "\n",
      "         term                                              Name  \\\n",
      "0  GO:0003674                                molecular_function   \n",
      "1  GO:0005488                                           binding   \n",
      "2  GO:0005515                                   protein binding   \n",
      "3  GO:0006139  nucleobase-containing compound metabolic process   \n",
      "4  GO:0006259                             DNA metabolic process   \n",
      "\n",
      "            Namespace                                          Embedding  \\\n",
      "0  molecular_function  [[[tensor(0.4123), tensor(0.0939), tensor(-0.0...   \n",
      "1  molecular_function  [[[tensor(0.4123), tensor(0.0939), tensor(-0.0...   \n",
      "2  molecular_function  [[[tensor(0.4123), tensor(0.0939), tensor(-0.0...   \n",
      "3  biological_process  [[[tensor(0.4123), tensor(0.0939), tensor(-0.0...   \n",
      "4  biological_process  [[[tensor(0.4123), tensor(0.0939), tensor(-0.0...   \n",
      "\n",
      "                                 Projected_Embedding  \n",
      "0  [-0.23285663, 0.15137367, 0.03970757, -0.04302...  \n",
      "1  [-0.23285663, 0.15137367, 0.03970757, -0.04302...  \n",
      "2  [-0.23285663, 0.15137367, 0.03970757, -0.04302...  \n",
      "3  [-0.23285663, 0.15137367, 0.03970757, -0.04302...  \n",
      "4  [-0.23285663, 0.15137367, 0.03970757, -0.04302...  \n",
      "Empty DataFrame\n",
      "Columns: [EntryID, Sequence, taxonomyID, term, Name, Namespace, Embedding, Projected_Embedding, EL_Embedding]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# 创建MLP模型实例\n",
    "input_dim = 1280  # ESM2 Embedding的维度\n",
    "output_dim = embedding_dim  # EL Embedding的维度\n",
    "mlp = MLP(input_dim, output_dim)\n",
    "\n",
    "# 投射蛋白质ESM Embedding\n",
    "def project_embedding(esm_embedding):\n",
    "    esm_embedding_tensor = torch.tensor(esm_embedding).float()\n",
    "    projected_embedding = mlp(esm_embedding_tensor)\n",
    "    return projected_embedding.detach().numpy()\n",
    "\n",
    "# 对每个蛋白质序列的ESM Embedding进行投射\n",
    "subset_train_total['Projected_Embedding'] = subset_train_total['Embedding'].apply(lambda x: project_embedding(x.mean(dim=1).squeeze().numpy()))\n",
    "\n",
    "# 打印部分结果\n",
    "print(subset_train_total.head())\n",
    "\n",
    "# 合并EL Embeddings与蛋白质的Projected Embedding\n",
    "final_df = pd.merge(subset_train_total, terms_df, on='term')\n",
    "\n",
    "# 打印最终的结果\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EntryID</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>taxonomyID</th>\n",
       "      <th>term</th>\n",
       "      <th>Name</th>\n",
       "      <th>Namespace</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Projected_Embedding</th>\n",
       "      <th>EL_Embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [EntryID, Sequence, taxonomyID, term, Name, Namespace, Embedding, Projected_Embedding, EL_Embedding]\n",
       "Index: []"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"facebook/esm-1b\"\n",
    "tokenizer = EsmTokenizer.from_pretrained(model_name)\n",
    "model = EsmModel.from_pretrained(model_name)\n",
    "\n",
    "def get_embedding(sequence):\n",
    "    inputs = tokenizer(sequence, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state\n",
    "\n",
    "train_total['Embedding'] = train_total['Sequence'].apply(get_embedding)\n",
    "\n",
    "train_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取GO术语并生成EL Embeddings\n",
    "def extract_terms_and_generate_embeddings(graph, namespaces, embedding_dim):\n",
    "    terms = []\n",
    "    embeddings = []\n",
    "    for node, data in graph.nodes(data=True):\n",
    "        if 'namespace' in data and data['namespace'] in namespaces:\n",
    "            terms.append(node)\n",
    "            embeddings.append(np.random.randn(embedding_dim))  # 示例中用随机向量表示\n",
    "    return terms, np.array(embeddings)\n",
    "\n",
    "# 假设EL Embedding的维度为256\n",
    "embedding_dim = 256\n",
    "graph = read_obo(par)\n",
    "terms, embeddings = extract_terms_and_generate_embeddings(graph, {\"molecular_function\", \"biological_process\", \"cellular_component\"}, embedding_dim)\n",
    "\n",
    "# 将GO术语和嵌入表示存储在DataFrame中\n",
    "terms_df = pd.DataFrame({'term': terms, 'EL_Embedding': list(embeddings)})\n",
    "\n",
    "# 打印部分结果\n",
    "print(terms_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from transformers import EsmTokenizer, EsmModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import obonet\n",
    "\n",
    "# 定义MLP模型\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.fc2 = nn.Linear(512, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# 创建MLP模型实例\n",
    "input_dim = 1280  # ESM2 Embedding的维度\n",
    "output_dim = embedding_dim  # EL Embedding的维度\n",
    "mlp = MLP(input_dim, output_dim)\n",
    "\n",
    "# 投射蛋白质ESM Embedding\n",
    "def project_embedding(esm_embedding):\n",
    "    esm_embedding_tensor = torch.tensor(esm_embedding).float()\n",
    "    projected_embedding = mlp(esm_embedding_tensor)\n",
    "    return projected_embedding.detach().numpy()\n",
    "\n",
    "# 对每个蛋白质序列的ESM Embedding进行投射\n",
    "train_total['Projected_Embedding'] = train_total['Embedding'].apply(lambda x: project_embedding(x.mean(dim=1).squeeze().numpy()))\n",
    "\n",
    "# 打印部分结果\n",
    "print(train_total.head())\n",
    "\n",
    "# 合并EL Embeddings与蛋白质的Projected Embedding\n",
    "final_df = pd.merge(train_total, terms_df, on='term')\n",
    "\n",
    "# 打印最终的结果\n",
    "print(final_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
